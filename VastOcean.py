import os
import openai
import glob
import shutil
import tiktoken
# Agent used to synthesize a final report from the individual summaries.
from pydantic import BaseModel
import time
from agents import Agent
from openai import AsyncOpenAI
from agents import Agent, WebSearchTool
from agents.model_settings import ModelSettings
from agents import Agent, OpenAIResponsesModel, WebSearchTool # å¯èƒ½è¿˜éœ€è¦å¯¼å…¥å…¶ä»–ä¸œè¥¿
from agents import OpenAIChatCompletionsModel,Agent,Runner,set_default_openai_client, set_tracing_disabled
from agents.model_settings import ModelSettings
from pydantic import BaseModel
from agents import Agent, WebSearchTool
from agents.model_settings import ModelSettings
import numpy as np
import pandas as pd
import pymysql
from openai import OpenAI
import os
from dotenv import load_dotenv
load_dotenv(override=True)
import nest_asyncio
nest_asyncio.apply()  # å…è®¸äº‹ä»¶å¾ªç¯åµŒå¥—
from agents import function_tool
import asyncio
import json
import io
import inspect
import requests
import re
import random
import string
import base64

import dateutil.parser as parser
import tiktoken

import sys
from dotenv import load_dotenv
from openai import OpenAI

import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'
os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'

class WebSearchItem(BaseModel):
    reason: str
    "Your reasoning for why this search is important to the query."

    query: str
    "The search term to use for the web search."

class WebSearchPlan(BaseModel):
    searches: list[WebSearchItem]
    """A list of web searches to perform to best answer the query."""

class ReportData(BaseModel):
    short_summary: str
    """A short 2-3 sentence summary of the findings."""

    markdown_report: str
    """The final report"""

    follow_up_questions: list[str]
    """Suggested topics to research further"""

class VastOcean:
    def __init__(self,messages=None):
        # å¯¼å…¥å¿…è¦çš„åº“
        import json
        import os
        import re
        import pymysql
        from openai import OpenAI
        # è®¾å®š token ä¸Šé™
        self.MAX_TOKENS_LIMIT = 12000 
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv(override=True)
        # æ¨¡å‹API-KEYåŠè¯·æ±‚åœ°å€
        self.API_KEY = os.getenv("API_KEY")
        self.MODEL = os.getenv("MODEL")
        self.BASE_URL = os.getenv("BASE_URL")

        self.github_token = os.getenv('GITHUB_TOKEN')
        self.bocha_web_search_api=os.getenv("BOCHA_WEB_SEARCH_API")
        # è°·æ­Œæœç´¢æœåŠ¡å™¨
        self.google_search_key = os.getenv("GOOGLE_SEARCH_API_KEY")
        self.cse_id = os.getenv("CSE_ID") # 
        self.search_user_agent = os.getenv("search_user_agent")
        self.host = os.getenv('HOST')
        self.user = os.getenv('USER')
        self.mysql_pw = os.getenv('MYSQL_PW')
        self.db = os.getenv('DB_NAME')
        self.port = os.getenv('PORT')
        self.python_inter_args = '{"py_code": "import numpy as np\\narr = np.array([1, 2, 3, 4])\\nsum_arr = np.sum(arr)\\nsum_arr"}'
        self.python_inter_tool = {
            "type": "function",
            "function": {
                "name": "python_inter",
                "description": f"å½“ç”¨æˆ·éœ€è¦ç¼–å†™Pythonç¨‹åºå¹¶æ‰§è¡Œæ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚è¯¥å‡½æ•°å¯ä»¥æ‰§è¡Œä¸€æ®µPythonä»£ç å¹¶è¿”å›æœ€ç»ˆç»“æœï¼Œéœ€è¦æ³¨æ„ï¼Œæœ¬å‡½æ•°åªèƒ½æ‰§è¡Œéç»˜å›¾ç±»çš„ä»£ç ï¼Œè‹¥æ˜¯ç»˜å›¾ç›¸å…³ä»£ç ï¼Œåˆ™éœ€è¦è°ƒç”¨fig_interå‡½æ•°è¿è¡Œã€‚\nåŒæ—¶éœ€è¦æ³¨æ„ï¼Œç¼–å†™å¤–éƒ¨å‡½æ•°çš„å‚æ•°æ¶ˆæ¯æ—¶ï¼Œå¿…é¡»æ˜¯æ»¡è¶³jsonæ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚å¦‚ä»¥ä¸‹å½¢å¼å­—ç¬¦ä¸²å°±æ˜¯åˆè§„å­—ç¬¦ä¸²ï¼š{self.python_inter_args}",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "py_code": {
                            "type": "string",
                            "description": "The Python code to execute."
                        },
                        "g": {
                            "type": "string",
                            "description": "Global environment variables, default to globals().",
                            "default": "globals()"
                        }
                    },
                    "required": ["py_code"]
                }
            }
        } 
        self.fig_inter_tool = {
            "type": "function",
            "function": {
                "name": "fig_inter",
                "description": (
                    "å½“ç”¨æˆ·éœ€è¦ä½¿ç”¨ Python è¿›è¡Œå¯è§†åŒ–ç»˜å›¾ä»»åŠ¡æ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚"
                    "è¯¥å‡½æ•°ä¼šæ‰§è¡Œç”¨æˆ·æä¾›çš„ Python ç»˜å›¾ä»£ç ï¼Œå¹¶è‡ªåŠ¨å°†ç”Ÿæˆçš„å›¾åƒå¯¹è±¡ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶å¹¶å±•ç¤ºã€‚\n\n"
                    "è°ƒç”¨è¯¥å‡½æ•°æ—¶ï¼Œè¯·ä¼ å…¥ä»¥ä¸‹å‚æ•°ï¼š\n\n"
                    "1. `py_code`: ä¸€ä¸ªå­—ç¬¦ä¸²å½¢å¼çš„ Python ç»˜å›¾ä»£ç ï¼Œ**å¿…é¡»æ˜¯å®Œæ•´ã€å¯ç‹¬ç«‹è¿è¡Œçš„è„šæœ¬**ï¼Œ"
                    "ä»£ç å¿…é¡»åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªå‘½åä¸º `fname` çš„ matplotlib å›¾åƒå¯¹è±¡ï¼›\n"
                    "2. `fname`: å›¾åƒå¯¹è±¡çš„å˜é‡åï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰ï¼Œä¾‹å¦‚ 'fig'ï¼›\n"
                    "3. `g`: å…¨å±€å˜é‡ç¯å¢ƒï¼Œé»˜è®¤ä¿æŒä¸º 'globals()' å³å¯ã€‚\n\n"
                    "ğŸ“Œ è¯·ç¡®ä¿ç»˜å›¾ä»£ç æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š\n"
                    "- åŒ…å«æ‰€æœ‰å¿…è¦çš„ importï¼ˆå¦‚ `import matplotlib.pyplot as plt`, `import seaborn as sns` ç­‰ï¼‰ï¼›\n"
                    "- å¿…é¡»åŒ…å«æ•°æ®å®šä¹‰ï¼ˆå¦‚ `df = pd.DataFrame(...)`ï¼‰ï¼Œä¸è¦ä¾èµ–å¤–éƒ¨å˜é‡ï¼›\n"
                    "- æ¨èä½¿ç”¨ `fig, ax = plt.subplots()` æ˜¾å¼åˆ›å»ºå›¾åƒï¼›\n"
                    "- ä½¿ç”¨ `ax` å¯¹è±¡è¿›è¡Œç»˜å›¾æ“ä½œï¼ˆä¾‹å¦‚ï¼š`sns.lineplot(..., ax=ax)`ï¼‰ï¼›\n"
                    "- æœ€åæ˜ç¡®å°†å›¾åƒå¯¹è±¡ä¿å­˜ä¸º `fname` å˜é‡ï¼ˆå¦‚ `fig = plt.gcf()`ï¼‰ã€‚\n\n"
                    "ğŸ“Œ ä¸éœ€è¦è‡ªå·±ä¿å­˜å›¾åƒï¼Œå‡½æ•°ä¼šè‡ªåŠ¨ä¿å­˜å¹¶å±•ç¤ºã€‚\n\n"
                    "âœ… åˆè§„ç¤ºä¾‹ä»£ç ï¼š\n"
                    "```python\n"
                    "import matplotlib.pyplot as plt\n"
                    "import seaborn as sns\n"
                    "import pandas as pd\n\n"
                    "df = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})\n"
                    "fig, ax = plt.subplots()\n"
                    "sns.lineplot(data=df, x='x', y='y', ax=ax)\n"
                    "ax.set_title('Line Plot')\n"
                    "fig = plt.gcf()  # ä¸€å®šè¦èµ‹å€¼ç»™ fname æŒ‡å®šçš„å˜é‡å\n"
                    "```"
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "py_code": {
                            "type": "string",
                            "description": (
                                "éœ€è¦æ‰§è¡Œçš„ Python ç»˜å›¾ä»£ç ï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰ã€‚"
                                "ä»£ç å¿…é¡»åˆ›å»ºä¸€ä¸ª matplotlib å›¾åƒå¯¹è±¡ï¼Œå¹¶èµ‹å€¼ä¸º `fname` æ‰€æŒ‡å®šçš„å˜é‡åã€‚"
                            )
                        },
                        "fname": {
                            "type": "string",
                            "description": "å›¾åƒå¯¹è±¡çš„å˜é‡åï¼ˆä¾‹å¦‚ 'fig'ï¼‰ï¼Œä»£ç ä¸­å¿…é¡»ä½¿ç”¨è¿™ä¸ªå˜é‡åä¿å­˜ç»˜å›¾å¯¹è±¡ã€‚"
                        },
                        "g": {
                            "type": "string",
                            "description": "è¿è¡Œç¯å¢ƒå˜é‡ï¼Œé»˜è®¤ä¿æŒä¸º 'globals()' å³å¯ã€‚",
                            "default": "globals()"
                        }
                    },
                    "required": ["py_code", "fname"]
                }
            }
        }
        self.sql_inter_args = '{"sql_query": "SHOW TABLES;"}'
        self.sql_inter_tool = {
            "type": "function",
            "function": {
                "name": "sql_inter",
                "description": (
                    "å½“ç”¨æˆ·éœ€è¦è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢å·¥ä½œæ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚"
                    "è¯¥å‡½æ•°ç”¨äºåœ¨æŒ‡å®šMySQLæœåŠ¡å™¨ä¸Šè¿è¡Œä¸€æ®µSQLä»£ç ï¼Œå®Œæˆæ•°æ®æŸ¥è¯¢ç›¸å…³å·¥ä½œï¼Œ"
                    "å¹¶ä¸”å½“å‰å‡½æ•°æ˜¯ä½¿ç”¨pymsqlè¿æ¥MySQLæ•°æ®åº“ã€‚"
                    "æœ¬å‡½æ•°åªè´Ÿè´£è¿è¡ŒSQLä»£ç å¹¶è¿›è¡Œæ•°æ®æŸ¥è¯¢ï¼Œè‹¥è¦è¿›è¡Œæ•°æ®æå–ï¼Œåˆ™ä½¿ç”¨å¦ä¸€ä¸ªextract_dataå‡½æ•°ã€‚"
                    "åŒæ—¶éœ€è¦æ³¨æ„ï¼Œç¼–å†™å¤–éƒ¨å‡½æ•°çš„å‚æ•°æ¶ˆæ¯æ—¶ï¼Œå¿…é¡»æ˜¯æ»¡è¶³jsonæ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ä»¥ä¸‹å½¢å¼å­—ç¬¦ä¸²å°±æ˜¯åˆè§„å­—ç¬¦ä¸²ï¼š"
                    f"{self.sql_inter_args}"
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "sql_query": {
                            "type": "string",
                            "description": "The SQL query to execute in MySQL database."
                        },
                        "g": {
                            "type": "string",
                            "description": "Global environment variables, default to globals().",
                            "default": "globals()"
                        }
                    },
                    "required": ["sql_query"]
                }
            }
        }
        self.extract_data_args = '{"sql_query": "SELECT * FROM users", "df_name": "users"}'
        self.extract_data_tool = {
            "type": "function",
            "function": {
                "name": "extract_data",
                "description": (
                    "ç”¨äºåœ¨MySQLæ•°æ®åº“ä¸­æå–ä¸€å¼ è¡¨åˆ°å½“å‰Pythonç¯å¢ƒä¸­ï¼Œæ³¨æ„ï¼Œæœ¬å‡½æ•°åªè´Ÿè´£æ•°æ®è¡¨çš„æå–ï¼Œ"
                    "å¹¶ä¸è´Ÿè´£æ•°æ®æŸ¥è¯¢ï¼Œè‹¥éœ€è¦åœ¨MySQLä¸­è¿›è¡Œæ•°æ®æŸ¥è¯¢ï¼Œè¯·ä½¿ç”¨sql_interå‡½æ•°ã€‚"
                    "åŒæ—¶éœ€è¦æ³¨æ„ï¼Œç¼–å†™å¤–éƒ¨å‡½æ•°çš„å‚æ•°æ¶ˆæ¯æ—¶ï¼Œå¿…é¡»æ˜¯æ»¡è¶³jsonæ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œ"
                    f"ä¾‹å¦‚å¦‚ä»¥ä¸‹å½¢å¼å­—ç¬¦ä¸²å°±æ˜¯åˆè§„å­—ç¬¦ä¸²ï¼š{self.extract_data_args}"
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "sql_query": {
                            "type": "string",
                            "description": "The SQL query to extract a table from MySQL database."
                        },
                        "df_name": {
                            "type": "string",
                            "description": "The name of the variable to store the extracted table in the local environment."
                        },
                        "g": {
                            "type": "string",
                            "description": "Global environment variables, default to globals().",
                            "default": "globals()"
                        }
                    },
                    "required": ["sql_query", "df_name"]
                }
            }
        }
        self.get_answer_tool = {
            "type": "function",
            "function": {
                "name": "get_answer",
                "description": (
                    "è”ç½‘æœç´¢å·¥å…·ï¼Œå½“ç”¨æˆ·æå‡ºçš„é—®é¢˜è¶…å‡ºä½ çš„çŸ¥è¯†åº“èŒƒç•´æ—¶ï¼Œæˆ–è¯¥é—®é¢˜ä½ ä¸çŸ¥é“ç­”æ¡ˆçš„æ—¶å€™ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°æ¥è·å¾—é—®é¢˜çš„ç­”æ¡ˆã€‚è¯¥å‡½æ•°ä¼šè‡ªåŠ¨ä»äº’è”ç½‘ä¸Šæœç´¢å¾—åˆ°é—®é¢˜ç›¸å…³æ–‡æœ¬ï¼Œè€Œåä½ å¯å›´ç»•æ–‡æœ¬å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œå¹¶å›ç­”ç”¨æˆ·æé—®ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå½“ç”¨æˆ·ç‚¹åè¦æ±‚æƒ³è¦äº†è§£GitHubä¸Šçš„é¡¹ç›®æ—¶å€™ï¼Œè¯·è°ƒç”¨get_answer_githubå‡½æ•°ã€‚"
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "q": {
                            "type": "string",
                            "description": "ä¸€ä¸ªæ»¡è¶³æœç´¢æ ¼å¼çš„é—®é¢˜ï¼Œç”¨å­—ç¬¦ä¸²å½¢å¼è¿›è¡Œè¡¨ç¤ºã€‚",
                            "example": "ä»€ä¹ˆæ˜¯MCP?"
                        },
                        "g": {
                            "type": "string",
                            "description": "Global environment variables, default to globals().",
                            "default": "globals()"
                        }
                    },
                    "required": ["q"]
                }
            }
        }
        self.get_answer_github_tool = {
            "type": "function",
            "function": {
                "name": "get_answer_github",
                "description": (
                    "GitHubè”ç½‘æœç´¢å·¥å…·ï¼Œå½“ç”¨æˆ·æå‡ºçš„é—®é¢˜è¶…å‡ºä½ çš„çŸ¥è¯†åº“èŒƒç•´æ—¶ï¼Œæˆ–è¯¥é—®é¢˜ä½ ä¸çŸ¥é“ç­”æ¡ˆçš„æ—¶å€™ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°æ¥è·å¾—é—®é¢˜çš„ç­”æ¡ˆã€‚"
                    "è¯¥å‡½æ•°ä¼šè‡ªåŠ¨ä»GitHubä¸Šæœç´¢å¾—åˆ°é—®é¢˜ç›¸å…³æ–‡æœ¬ï¼Œè€Œåä½ å¯å›´ç»•æ–‡æœ¬å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œå¹¶å›ç­”ç”¨æˆ·æé—®ã€‚"
                    "éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå½“ç”¨æˆ·æé—®ç‚¹åè¦æ±‚åœ¨GitHubè¿›è¡Œæœç´¢æ—¶ï¼Œä¾‹å¦‚'è¯·å¸®æˆ‘ä»‹ç»ä¸‹GitHubä¸Šçš„Qwen3é¡¹ç›®'ï¼Œæ­¤æ—¶è¯·è°ƒç”¨è¯¥å‡½æ•°ï¼Œ"
                    "å…¶ä»–æƒ…å†µä¸‹è¯·è°ƒç”¨get_answerå¤–éƒ¨å‡½æ•°å¹¶è¿›è¡Œå›ç­”ã€‚"
                ),
                "parameters": {
                    "type": "object",
                    "properties": {
                        "q": {
                            "type": "string",
                            "description": "ä¸€ä¸ªæ»¡è¶³GitHubæœç´¢æ ¼å¼çš„é—®é¢˜ï¼Œå¾€å¾€æ˜¯éœ€è¦ä»ç”¨æˆ·é—®é¢˜ä¸­æå‡ºä¸€ä¸ªé€‚åˆæœç´¢çš„é¡¹ç›®å…³é”®è¯ï¼Œç”¨å­—ç¬¦ä¸²å½¢å¼è¿›è¡Œè¡¨ç¤ºã€‚",
                            "example": "DeepSeek-R1"
                        },
                        "g": {
                            "type": "string",
                            "description": "Global environment variables, default to globals().",
                            "default": "globals()"
                        }
                    },
                    "required": ["q"]
                }
            }
        }
        self.prompt_style1 = """
        ä½ æ˜¯ä¸€åä¸“ä¸šä¸”ç»†è‡´çš„åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯åœ¨ç”¨æˆ·æå‡ºé—®é¢˜åï¼Œé€šè¿‡å‹å¥½ä¸”æœ‰å¼•å¯¼æ€§çš„è¿½é—®ï¼Œæ›´æ·±å…¥åœ°ç†è§£ç”¨æˆ·çœŸæ­£çš„éœ€æ±‚èƒŒæ™¯ã€‚è¿™æ ·ï¼Œä½ æ‰èƒ½æä¾›æ›´ç²¾å‡†å’Œæ›´æœ‰æ•ˆçš„å¸®åŠ©ã€‚
        å½“ç”¨æˆ·æå‡ºä¸€ä¸ªå®½æ³›æˆ–è€…ä¸å¤Ÿæ˜ç¡®çš„é—®é¢˜æ—¶ï¼Œä½ åº”å½“ç§¯æä¸»åŠ¨åœ°æå‡ºåç»­é—®é¢˜ï¼Œå¼•å¯¼ç”¨æˆ·æä¾›æ›´å¤šèƒŒæ™¯å’Œç»†èŠ‚ï¼Œä»¥å¸®åŠ©ä½ æ›´å‡†ç¡®åœ°å›åº”ã€‚
        ç¤ºä¾‹å¼•å¯¼é—®é¢˜ï¼š
        
        ç”¨æˆ·æé—®ç¤ºä¾‹ï¼š
        æœ€è¿‘ï¼Œåœ¨å¤§æ¨¡å‹æŠ€æœ¯é¢†åŸŸï¼Œæœ‰ä¸€é¡¹éå¸¸çƒ­é—¨çš„æŠ€æœ¯ï¼Œåå«MCPï¼Œmodel context protocolï¼Œè°ƒç”¨å¹¶æ·±åº¦æ€»ç»“ï¼Œè¿™é¡¹æŠ€æœ¯ä¸OpenAIæå‡ºçš„function callingä¹‹é—´çš„åŒºåˆ«ã€‚
        
        ä½ åº”è¯¥ç»™å‡ºçš„å¼•å¯¼å¼å›åº”ç¤ºä¾‹ï¼š
        åœ¨æ¯”è¾ƒMCPï¼ˆModel Context Protocolï¼‰ä¸OpenAIçš„Function Callingæ—¶ï¼Œæˆ‘å¯ä»¥æ¶µç›–ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
        - å®šä¹‰å’ŒåŸºæœ¬æ¦‚å¿µï¼šMCPå’ŒFunction Callingçš„åŸºæœ¬åŸç†å’Œç›®æ ‡ã€‚
        - å·¥ä½œæœºåˆ¶ï¼šå®ƒä»¬å¦‚ä½•å¤„ç†æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºã€‚
        - åº”ç”¨åœºæ™¯ï¼šå®ƒä»¬åˆ†åˆ«é€‚ç”¨äºå“ªäº›å…·ä½“åœºæ™¯ï¼Ÿ
        - æŠ€æœ¯ä¼˜åŠ¿ä¸å±€é™æ€§ï¼šå„è‡ªçš„ä¼˜åŠ£åŠ¿åˆ†æã€‚
        - ç”Ÿæ€å’Œå…¼å®¹æ€§ï¼šå®ƒä»¬æ˜¯å¦èƒ½ä¸ç°æœ‰çš„å¤§æ¨¡å‹å’Œåº”ç”¨é›†æˆã€‚
        - æœªæ¥å‘å±•è¶‹åŠ¿ï¼šè¿™äº›æŠ€æœ¯æœªæ¥çš„å‘å±•æ–¹å‘ã€‚
        è¯·é—®ä½ æ˜¯å¦å¸Œæœ›æˆ‘ç‰¹åˆ«å…³æ³¨æŸäº›æ–¹é¢ï¼Œæˆ–è€…æœ‰ç‰¹å®šçš„æŠ€æœ¯ç»†èŠ‚éœ€è¦æ·±å…¥åˆ†æï¼Ÿ
        
        å†æ¯”å¦‚ç”¨æˆ·æé—®ï¼š
        è¯·ä½ å¸®æˆ‘è¯¦ç»†æ•´ç†ï¼Œåä¸º910B2xé²²é¹920ï¼Œå¦‚ä½•éƒ¨ç½²DeepSeekæ¨¡å‹ã€‚
        
        ä½ åº”è¯¥ç»™å‡ºçš„å¼•å¯¼å¼å›åº”ç¤ºä¾‹ï¼š
        è¯·æä¾›ä»¥ä¸‹è¯¦ç»†ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘èƒ½ä¸ºæ‚¨æ•´ç†å®Œæ•´çš„éƒ¨ç½²æŒ‡å—ï¼š
        1. æ‚¨å¸Œæœ›éƒ¨ç½²çš„DeepSeekæ¨¡å‹å…·ä½“æ˜¯å“ªä¸€ä¸ªï¼Ÿï¼ˆä¾‹å¦‚DeepSeek-VLã€DeepSeek-Coderç­‰ï¼‰
        2. ç›®æ ‡ç³»ç»Ÿç¯å¢ƒï¼ˆæ“ä½œç³»ç»Ÿã€å·²æœ‰è½¯ä»¶ç¯å¢ƒç­‰ï¼‰ï¼Ÿ
        3. æ˜¯å¦æœ‰ç‰¹å®šçš„æ·±åº¦å­¦ä¹ æ¡†æ¶è¦æ±‚ï¼Ÿï¼ˆå¦‚PyTorchã€TensorFlowï¼‰
        4. æ˜¯å¦éœ€è¦ä¼˜åŒ–éƒ¨ç½²ï¼ˆå¦‚ä½¿ç”¨æ˜‡è…¾NPUåŠ é€Ÿï¼‰ï¼Ÿ
        5. æœŸæœ›çš„ä½¿ç”¨åœºæ™¯ï¼Ÿï¼ˆå¦‚æ¨ç†ã€è®­ç»ƒã€å¾®è°ƒç­‰ï¼‰
        è¯·æä¾›è¿™äº›ä¿¡æ¯åï¼Œæˆ‘å°†ä¸ºæ‚¨æ•´ç†å…·ä½“çš„éƒ¨ç½²æ­¥éª¤ã€‚
        
        è®°ä½ï¼Œä¿æŒå‹å¥½è€Œä¸“ä¸šçš„æ€åº¦ï¼Œä¸»åŠ¨å¸®åŠ©ç”¨æˆ·æ˜ç¡®éœ€æ±‚ï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡ºä¸å¤Ÿç²¾å‡†çš„å›ç­”ã€‚ç°åœ¨ç”¨æˆ·æå‡ºé—®é¢˜å¦‚ä¸‹ï¼š{}ï¼Œè¯·æŒ‰ç…§è¦æ±‚è¿›è¡Œå›å¤ã€‚
        """
        self.prompt_style2 = """
        ä½ æ˜¯ä¸€ä½çŸ¥è¯†å¹¿åšã€æ“…é•¿åˆ©ç”¨å¤šç§å¤–éƒ¨å·¥å…·çš„èµ„æ·±ç ”ç©¶å‘˜ã€‚å½“ç”¨æˆ·å·²æ˜ç¡®æå‡ºå…·ä½“éœ€æ±‚ï¼š{}ï¼Œç°åœ¨ä½ çš„ä»»åŠ¡æ˜¯ï¼š
        é¦–å…ˆæ˜ç¡®ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒåŠç›¸å…³ç»†èŠ‚ã€‚
        å°½å¯èƒ½è°ƒç”¨å¯ç”¨çš„å¤–éƒ¨å·¥å…·ï¼ˆä¾‹å¦‚ï¼šè”ç½‘æœç´¢å·¥å…·get_answerã€GitHubæœç´¢å·¥å…·get_answer_githubã€æœ¬åœ°ä»£ç è¿è¡Œå·¥å…·python_interä»¥åŠå…¶ä»–å·¥å…·ï¼‰ï¼Œå›´ç»•ç”¨æˆ·ç»™å‡ºçš„åŸå§‹é—®é¢˜å’Œè¡¥å……ç»†èŠ‚ï¼Œè¿›è¡Œå¹¿æ³›è€Œæ·±å…¥çš„ä¿¡æ¯æ”¶é›†ã€‚
        ç»¼åˆåˆ©ç”¨ä½ ä»å„ç§å·¥å…·ä¸­è·å–çš„ä¿¡æ¯ï¼Œæä¾›è¯¦ç»†ã€å…¨é¢ã€ä¸“ä¸šä¸”å…·æœ‰æ·±åº¦çš„è§£ç­”ã€‚ä½ çš„å›ç­”åº”å°½é‡è¾¾åˆ°2000å­—ä»¥ä¸Šï¼Œå†…å®¹ä¸¥è°¨å‡†ç¡®ä¸”å¯Œæœ‰æ´å¯ŸåŠ›ã€‚
        
        ç¤ºä¾‹æµç¨‹ï¼š
        ç”¨æˆ·æ˜ç¡®éœ€æ±‚ç¤ºä¾‹ï¼š
        æˆ‘ç›®å‰æ­£åœ¨å­¦ä¹  ModelContextProtocolï¼ˆMCPï¼‰ï¼Œä¸»è¦å…³æ³¨å®ƒåœ¨AIæ¨¡å‹å¼€å‘é¢†åŸŸä¸­çš„å…·ä½“åº”ç”¨åœºæ™¯ã€æŠ€æœ¯ç»†èŠ‚å’Œä¸€äº›ä¸šç•Œæœ€æ–°çš„è¿›å±•ã€‚
        ä½ çš„å›åº”æµç¨‹ç¤ºä¾‹ï¼š
        é¦–å…ˆé‡è¿°å¹¶ç¡®è®¤ç”¨æˆ·çš„å…·ä½“éœ€æ±‚ã€‚
        æ˜ç¡®ä½ å°†è°ƒç”¨å“ªäº›å¤–éƒ¨å·¥å…·ï¼Œä¾‹å¦‚ï¼š
        ä½¿ç”¨è”ç½‘æœç´¢å·¥å…·æŸ¥è¯¢å®˜æ–¹æˆ–æƒå¨æ–‡æ¡£å¯¹ MCP åœ¨AIæ¨¡å‹å¼€å‘é¢†åŸŸçš„å…·ä½“åº”ç”¨è¯´æ˜ï¼›
        è°ƒç”¨GitHubæœç´¢å·¥å…·ï¼Œå¯»æ‰¾ä¸šç•Œé’ˆå¯¹MCPæŠ€æœ¯é¡¹ç›®ï¼›
        æ•´ç†å¹¶åˆ†æé€šè¿‡å·¥å…·è·å–çš„ä¿¡æ¯ï¼Œå½¢æˆä¸€ç¯‡é€»è¾‘æ¸…æ™°ã€ç»“æ„åˆç†çš„æ·±åº¦æŠ¥å‘Šã€‚
        
        å†æ¯”å¦‚ç”¨æˆ·éœ€è¦ç¼–å†™æ•°æ®åˆ†ææŠ¥å‘Šç¤ºä¾‹ï¼š
        æˆ‘æƒ³é’ˆå¯¹æŸç”µä¿¡å…¬å¸è¿‡å»ä¸€å¹´çš„ç”¨æˆ·æ•°æ®ï¼Œç¼–å†™ä¸€ä»½è¯¦ç»†çš„ç”¨æˆ·æµå¤±é¢„æµ‹æ•°æ®åˆ†ææŠ¥å‘Šï¼ŒæŠ¥å‘Šéœ€è¦åŒ…æ‹¬ç”¨æˆ·æµå¤±è¶‹åŠ¿åˆ†æã€æµå¤±ç”¨æˆ·ç‰¹å¾åˆ†æã€å½±å“ç”¨æˆ·æµå¤±çš„å…³é”®å› ç´ åˆ†æï¼Œå¹¶ç»™å‡ºæœªæ¥å‡å°‘ç”¨æˆ·æµå¤±çš„ç­–ç•¥å»ºè®®ã€‚
        ä½ çš„å›åº”æµç¨‹ç¤ºä¾‹ï¼š
        æ˜ç¡®å¹¶ç¡®è®¤ç”¨æˆ·éœ€æ±‚ï¼ŒæŒ‡å‡ºåˆ†æå†…å®¹åŒ…æ‹¬ç”¨æˆ·æµå¤±è¶‹åŠ¿ã€æµå¤±ç”¨æˆ·ç‰¹å¾ã€å…³é”®å½±å“å› ç´ ä»¥åŠç­–ç•¥å»ºè®®ã€‚
        æ˜ç¡®ä½ å°†è°ƒç”¨å“ªäº›å¤–éƒ¨å·¥å…·ï¼Œä¾‹å¦‚ï¼š
        ä½¿ç”¨æ•°æ®åˆ†æå·¥å…·å¯¹æä¾›çš„ç”¨æˆ·æ•°æ®è¿›è¡Œæµå¤±è¶‹åŠ¿åˆ†æï¼Œç”Ÿæˆè¶‹åŠ¿å›¾è¡¨ï¼›
        ä½¿ç”¨ä»£ç æ‰§è¡Œç¯å¢ƒï¼ˆå¦‚è°ƒç”¨python_interå·¥å…·ï¼‰å¯¹æµå¤±ç”¨æˆ·è¿›è¡Œç‰¹å¾åˆ†æï¼Œç¡®å®šå…¸å‹ç‰¹å¾ï¼›
        é€šè¿‡ç»Ÿè®¡åˆ†æå·¥å…·è¯†åˆ«å½±å“ç”¨æˆ·æµå¤±çš„å…³é”®å› ç´ ï¼ˆå¦‚æœåŠ¡è´¨é‡ã€ä»·æ ¼æ•æ„Ÿåº¦ã€ç«äº‰å¯¹æ‰‹ä¿ƒé”€ï¼‰ï¼ŒåŒæ—¶å€ŸåŠ©ç»˜å›¾å·¥å…·ï¼ˆfig_interï¼‰è¿›è¡Œé‡è¦ä¿¡æ¯å¯è§†åŒ–å±•ç¤ºï¼›
        ä½¿ç”¨äº’è”ç½‘æ£€ç´¢å·¥å…·æ£€ç´¢è¡Œä¸šå†…æœ€æ–°çš„å®¢æˆ·ä¿ç•™ç­–ç•¥ä¸å®è·µï¼Œæå‡ºæœ‰æ•ˆçš„ç­–ç•¥å»ºè®®ã€‚
        
        è®°ä½ï¼Œå›ç­”åŠ¡å¿…è¯¦ç»†å®Œæ•´ï¼Œå­—æ•°è‡³å°‘åœ¨2000å­—ä»¥ä¸Šï¼Œæ¸…æ™°å±•ç¤ºä½ æ˜¯å¦‚ä½•è¿ç”¨å„ç§å¤–éƒ¨å·¥å…·è¿›è¡Œæ·±å…¥ç ”ç©¶å¹¶å½¢æˆä¸“ä¸šç»“è®ºçš„ã€‚
        
        """
        self.tools = [self.sql_inter_tool, self.extract_data_tool, self.python_inter_tool, self.fig_inter_tool, self.get_answer_tool, self.get_answer_github_tool]
        if messages != None:
            self.messages = messages
        else:
            self.messages = [{
                "role": "system", 
                "content": "ä½ æ˜¯VastOceanï¼Œä¸€ååŠ©æ‰‹ã€‚"
            }]
        self.client = OpenAI(api_key=self.API_KEY, base_url=self.BASE_URL)
        # å®ä¾‹åŒ–å®¢æˆ·ç«¯
        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        self.OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")
        self.openai_sdk_client = OpenAI(api_key=self.OPENAI_API_KEY,  base_url=self.OPENAI_BASE_URL)        
        # OpenAI å®¢æˆ·ç«¯
        self.openai_client = AsyncOpenAI(
            base_url=self.OPENAI_BASE_URL,
            api_key=self.OPENAI_API_KEY,
        )
        self.PLAN_PROMPT = (
            "You are a helpful research assistant. Given a query, come up with a set of web searches "
            "to perform to best answer the query. Output between 10 and 20 terms to query for."
        )
        set_default_openai_client(self.openai_client)
        set_tracing_disabled(True)
        self.planner_agent = Agent(
            name="PlannerAgent",
            instructions=self.PLAN_PROMPT,
            model="gpt-4.1",
            output_type=WebSearchPlan,
        )
        self.SEARCH_INSTRUCTIONS = (
            "You are a research assistant. Given a search term, you search the web for that term and "
            "produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300 "
            "words. Capture the main points. Write succinctly, no need to have complete sentences or good "
            "grammar. This will be consumed by someone synthesizing a report, so its vital you capture the "
            "essence and ignore any fluff. Do not include any additional commentary other than the summary "
            "itself."
        )
        # ä½ æ˜¯ä¸€åç ”ç©¶åŠ©ç†ã€‚ç»™å®šä¸€ä¸ªæœç´¢è¯ï¼Œä½ éœ€è¦åœ¨äº’è”ç½‘ä¸Šæœç´¢è¯¥è¯ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ€»ç»“ï¼Œæ€»ç»“åº”åŒ…å«2-3æ®µæ–‡å­—ï¼Œå­—æ•°å°‘äº300å­—ã€‚æ•æ‰ä¸»è¦è¦ç‚¹ï¼Œç®€æ´æ˜äº†ï¼Œæ— éœ€å®Œæ•´å¥å­æˆ–è‰¯å¥½è¯­æ³•ã€‚è¿™å°†è¢«ç”¨äºåˆæˆæŠ¥å‘Šï¼Œå› æ­¤æ•æ‰æ ¸å¿ƒå†…å®¹å¹¶å¿½ç•¥ä»»ä½•å†—ä½™ä¿¡æ¯è‡³å…³é‡è¦ã€‚é™¤äº†æ€»ç»“æœ¬èº«ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯„è®ºã€‚
        self.search_agent = Agent(
            name="Search agent",
            instructions=self.SEARCH_INSTRUCTIONS,
            tools=[WebSearchTool()],
            model_settings=ModelSettings(tool_choice="required"),
            model="gpt-4.1",
        )
        self.REPORT_PROMPT_1 = (
            "You are a senior researcher tasked with writing a cohesive report for a research query. "
            "You will be provided with the original query, and some initial research done by a research "
            "assistant.\n"
            "You should first come up with an outline for the report that describes the structure and "
            "flow of the report. Then, generate the report and return that as your final output.\n"
            "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
            "for 5-10 pages of content, at least 1000 words."
        )
        self.REPORT_PROMPT_2= (
            "You are a senior researcher tasked with writing a cohesive report for a research query. "
            "You will be provided with the original query, and some initial research done by a research "
            "assistant.\n"
            "You should first come up with an outline for the report that describes the structure and "
            "flow of the report. Then, generate the report and return that as your final output.\n"
            "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
            "for 10-20 pages of content, at least 1500 words."
            "æœ€ç»ˆç»“æœè¯·ç”¨ä¸­æ–‡è¾“å‡ºã€‚"
        )
        self.writer_agent = Agent(
            name="WriterAgent",
            instructions=self.REPORT_PROMPT_2,
            model="gpt-4.1",
            output_type=ReportData,
        )

        try:
            print("æ­£åœ¨æµ‹è¯•æ¨¡å‹èƒ½å¦æ­£å¸¸è°ƒç”¨...")
            self.models = self.client.models.list()
            
            if self.models:
                print("â–Œ VastOceanåˆå§‹åŒ–å®Œæˆï¼Œæ¬¢è¿ä½¿ç”¨ï¼")
            else:
                print("æ¨¡å‹æ— æ³•è°ƒç”¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œç¯å¢ƒæˆ–æœ¬åœ°æ¨¡å‹é…ç½®ã€‚")

        except Exception as e:
            print("åˆå§‹åŒ–å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œæˆ–é…ç½®é”™è¯¯ã€‚è¯¦ç»†ä¿¡æ¯ï¼š", str(e))


    def python_inter(self, py_code : str, g='globals()') -> str:
        """
        ä¸“é—¨ç”¨äºæ‰§è¡Œpythonä»£ç ï¼Œå¹¶è·å–æœ€ç»ˆæŸ¥è¯¢æˆ–å¤„ç†ç»“æœã€‚
        :param py_code: å­—ç¬¦ä¸²å½¢å¼çš„Pythonä»£ç ï¼Œ
        :param g: gï¼Œå­—ç¬¦ä¸²å½¢å¼å˜é‡ï¼Œè¡¨ç¤ºç¯å¢ƒå˜é‡ï¼Œæ— éœ€è®¾ç½®ï¼Œä¿æŒé»˜è®¤å‚æ•°å³å¯
        æ ¸å¿ƒä½œç”¨: å……å½“ä»£ç æ‰§è¡Œçš„"ç¯å¢ƒ"æˆ–"å‘½åç©ºé—´" (Namespace)
        :returnï¼šä»£ç è¿è¡Œçš„æœ€ç»ˆç»“æœ
        """    
        print("æ­£åœ¨è°ƒç”¨python_interå·¥å…·è¿è¡ŒPythonä»£ç ...")
        try:
            # å°è¯•å¦‚æœæ˜¯è¡¨è¾¾å¼ï¼Œåˆ™è¿”å›è¡¨è¾¾å¼è¿è¡Œç»“æœ
            return str(eval(py_code, g))
        # è‹¥æŠ¥é”™ï¼Œåˆ™å…ˆæµ‹è¯•æ˜¯å¦æ˜¯å¯¹ç›¸åŒå˜é‡é‡å¤èµ‹å€¼
        except Exception as e:
            global_vars_before = set(g.keys())
            try:            
                exec(py_code, g)
            except Exception as e:
                return f"ä»£ç æ‰§è¡Œæ—¶æŠ¥é”™{e}"
            global_vars_after = set(g.keys())
            new_vars = global_vars_after - global_vars_before
            # è‹¥å­˜åœ¨æ–°å˜é‡
            if new_vars:
                result = {var: g[var] for var in new_vars}
                print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
                return str(result)
            else:
                print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
                return "å·²ç»é¡ºåˆ©æ‰§è¡Œä»£ç "

    def fig_inter(self, py_code, fname, g='globals()'):
        print("æ­£åœ¨è°ƒç”¨fig_interå·¥å…·è¿è¡ŒPythonä»£ç ...")
        import matplotlib
        # Explicitly use a non-interactive backend suitable for saving files
        # matplotlib.use('Agg') # Uncomment this line if you encounter backend issues
        import os
        import matplotlib.pyplot as plt
        import seaborn as sns
        import pandas as pd


        # ç”¨äºæ‰§è¡Œä»£ç çš„æœ¬åœ°å˜é‡
        local_vars = {"plt": plt, "pd": pd, "sns": sns}

        # ç›¸å¯¹è·¯å¾„ä¿å­˜ç›®å½•
        pics_dir = 'pics'
        if not os.path.exists(pics_dir):
            os.makedirs(pics_dir)

        try:
            # æ‰§è¡Œç”¨æˆ·ä»£ç 
            exec(py_code, g, local_vars)
            # Update global environment if needed (optional, based on original logic)
            # g.update(local_vars) # Consider if this update is necessary outside IPython context

            # è·å–å›¾åƒå¯¹è±¡
            # Try getting the figure from plt or local_vars
            fig = local_vars.get(fname, None)
            if fig is None and plt.gcf().get_axes(): # Check if there's an active figure managed by plt
                 fig = plt.gcf()

            if fig and fig.get_axes(): # Check if the figure actually contains something
                rel_path = os.path.join(pics_dir, f"{fname}.png")
                fig.savefig(rel_path, bbox_inches='tight')
                # display(Image(filename=rel_path)) # Removed for non-notebook environment
                plt.close(fig) # Close the figure to free memory
                print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œå›¾åƒå·²ä¿å­˜ã€‚")
                return f"âœ… å›¾ç‰‡å·²æˆåŠŸä¿å­˜è‡³: {rel_path}"
            elif fname in local_vars and not isinstance(local_vars[fname], plt.Figure):
                 return f"âš ï¸ ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œä½†å˜é‡ '{fname}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ Matplotlib Figure å¯¹è±¡ã€‚"
            else:
                # Check if plt was used directly without assigning to fname
                if plt.gcf().get_axes():
                     rel_path = os.path.join(pics_dir, f"{fname}.png")
                     plt.savefig(rel_path, bbox_inches='tight')
                     plt.close(plt.gcf()) # Close the figure
                     print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œä½¿ç”¨ plt ç›´æ¥ç”Ÿæˆçš„å›¾åƒå·²ä¿å­˜ã€‚")
                     return f"âœ… å›¾ç‰‡å·²æˆåŠŸä¿å­˜è‡³: {rel_path} (é€šè¿‡ plt ç›´æ¥ä¿å­˜)"
                else:
                    return "âš ï¸ ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œä½†æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒå¯¹è±¡æˆ–ç»˜å›¾å†…å®¹ã€‚è¯·ç¡®ä¿ä»£ç ç”Ÿæˆäº†å›¾åƒå¹¶èµ‹å€¼ç»™å˜é‡ '{fname}' æˆ–ä½¿ç”¨äº† pltã€‚"

        except Exception as e:
            # Ensure any open figures are closed on error too
            plt.close('all')
            return f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{e}"
        # finally:
            # matplotlib.use(current_backend) # Removed for non-notebook environment

    def sql_inter(self,sql_query, g='globals()'):
        """
        ç”¨äºæ‰§è¡Œä¸€æ®µSQLä»£ç ï¼Œå¹¶æœ€ç»ˆè·å–SQLä»£ç æ‰§è¡Œç»“æœï¼Œ\
        æ ¸å¿ƒåŠŸèƒ½æ˜¯å°†è¾“å…¥çš„SQLä»£ç ä¼ è¾“è‡³MySQLç¯å¢ƒä¸­è¿›è¡Œè¿è¡Œï¼Œ\
        å¹¶æœ€ç»ˆè¿”å›SQLä»£ç è¿è¡Œç»“æœã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæœ¬å‡½æ•°æ˜¯å€ŸåŠ©pymysqlæ¥è¿æ¥MySQLæ•°æ®åº“ã€‚
        :param sql_query: å­—ç¬¦ä¸²å½¢å¼çš„SQLæŸ¥è¯¢è¯­å¥ï¼Œç”¨äºæ‰§è¡Œå¯¹MySQLä¸­telco_dbæ•°æ®åº“ä¸­å„å¼ è¡¨è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶è·å¾—å„è¡¨ä¸­çš„å„ç±»ç›¸å…³ä¿¡æ¯
        :param g: gï¼Œå­—ç¬¦ä¸²å½¢å¼å˜é‡ï¼Œè¡¨ç¤ºç¯å¢ƒå˜é‡ï¼Œæ— éœ€è®¾ç½®ï¼Œä¿æŒé»˜è®¤å‚æ•°å³å¯
        :returnï¼šsql_queryåœ¨MySQLä¸­çš„è¿è¡Œç»“æœã€‚
        """
        print("æ­£åœ¨è°ƒç”¨sql_interå·¥å…·è¿è¡ŒSQLä»£ç ...")

        connection = pymysql.connect(
            host = self.host,  
            user = self.user, 
            passwd = self.mysql_pw,  
            db = self.db,
            port = int(self.port),
            charset='utf8',
        )
        
        try:
            with connection.cursor() as cursor:
                sql = sql_query
                cursor.execute(sql)
                results = cursor.fetchall()
                print("SQLä»£ç å·²é¡ºåˆ©è¿è¡Œï¼Œæ­£åœ¨æ•´ç†ç­”æ¡ˆ...")

        finally:
            connection.close()

        return json.dumps(results)

    def extract_data(self,sql_query, df_name, g='globals()'):
        """
        å€ŸåŠ©pymysqlå°†MySQLæ•°æ®åº“ä¸­çš„æŸå¼ è¡¨è¯»å–å¹¶ä¿å­˜åˆ°æœ¬åœ°Pythonç¯å¢ƒä¸­ã€‚
        :param sql_query: å­—ç¬¦ä¸²å½¢å¼çš„SQLæŸ¥è¯¢è¯­å¥ï¼Œç”¨äºæå–MySQLä¸­çš„æŸå¼ è¡¨ã€‚
        :param df_name: å°†MySQLæ•°æ®åº“ä¸­æå–çš„è¡¨æ ¼è¿›è¡Œæœ¬åœ°ä¿å­˜æ—¶çš„å˜é‡åï¼Œä»¥å­—ç¬¦ä¸²å½¢å¼è¡¨ç¤ºã€‚
        :param g: gï¼Œå­—ç¬¦ä¸²å½¢å¼å˜é‡ï¼Œè¡¨ç¤ºç¯å¢ƒå˜é‡ï¼Œæ— éœ€è®¾ç½®ï¼Œä¿æŒé»˜è®¤å‚æ•°å³å¯
        :returnï¼šè¡¨æ ¼è¯»å–å’Œä¿å­˜ç»“æœ
        """
        print("æ­£åœ¨è°ƒç”¨extract_dataå·¥å…·è¿è¡ŒSQLä»£ç ...")
        
        connection = pymysql.connect(
            host = self.host,  
            user = self.user, 
            passwd = self.mysql_pw,  
            db = self.db,
            port = int(self.port),
            charset='utf8',
        )
        
        print("æ­£åœ¨è¿æ¥æ•°æ®åº“...")
        print(f"æ•°æ®åº“è¿æ¥æˆåŠŸ: {connection}")

        try:
            g[df_name] = pd.read_sql(sql_query, connection)
            print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return f"âœ… æ•°æ®å·²æˆåŠŸä¿å­˜è‡³: {df_name}"
        except Exception as e:
            print(f"extract_dataæ‰§è¡Œå‡ºé”™: {e}")
            return f"âŒ æ‰§è¡Œå¤±è´¥: {e}"
        finally:
            print("æ­£åœ¨å…³é—­æ•°æ®åº“è¿æ¥...")
            if 'connection' in locals() and connection:
                connection.close()
    
    def google_search(self,query, num_results=10, site_url=None):
        
        url = "https://www.googleapis.com/customsearch/v1"

        # API è¯·æ±‚å‚æ•°
        if site_url == None:
            params = {
            'q': query,          
            'key': self.google_search_key,      
            'cx': self.cse_id,        
            'num': num_results   
            }
        else:
            params = {
            'q': query,         
            'key': self.google_search_key,      
            'cx': self.cse_id,        
            'num': num_results,  
            'siteSearch': site_url
            }

        # å‘é€è¯·æ±‚
        response = requests.get(url, params=params)
        response.raise_for_status()

        # è§£æå“åº”
        search_results = response.json().get('items', [])

        # æå–æ‰€éœ€ä¿¡æ¯
        results = [{
            'title': item['title'],
            'link': item['link'],
            'snippet': item['snippet']
        } for item in search_results]

        return results

    def process_bocha_results(self,search_results, include_images=True):
        """å¤„ç†åšæŸ¥æœç´¢APIçš„è¿”å›ç»“æœï¼Œæå–æ ‡é¢˜ã€é“¾æ¥ã€æ‘˜è¦ä»¥åŠå›¾ç‰‡ä¿¡æ¯
        
        :param search_results: åšæŸ¥æœç´¢APIè¿”å›çš„JSONç»“æœ
        :param include_images: æ˜¯å¦åŒ…å«å›¾ç‰‡ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºTrue
        :return: æå–åçš„ç»“æœå­—å…¸ï¼ŒåŒ…å«ç½‘é¡µç»“æœå’Œå›¾ç‰‡ç»“æœ
        """
        processed_results = {
            'web_results': [],
            'image_results': []
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
        if not search_results or 'data' not in search_results:
            print("æœç´¢ç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            return processed_results
        
        # ä»ç»“æœä¸­æå–ç½‘é¡µä¿¡æ¯
        data = search_results.get('data', {})
        web_pages = data.get('webPages', {})
        web_results_list = web_pages.get('value', [])
        
        # æå–æ¯ä¸ªç½‘é¡µç»“æœçš„title, linkå’Œsnippet
        for item in web_results_list:
            processed_results['web_results'].append({
                'title': item.get('name', 'æ— æ ‡é¢˜'),
                'link': item.get('url', 'æ— é“¾æ¥'),
                'snippet': item.get('snippet', 'æ— æ‘˜è¦'),
                'summary': item.get('summary', 'æ— æ€»ç»“')
            })
        
        # å¦‚æœéœ€è¦æå–å›¾ç‰‡ä¿¡æ¯
        if include_images and 'images' in data and data['images'] and 'value' in data['images']:
            image_results_list = data['images']['value']
            
            # æå–æ¯ä¸ªå›¾ç‰‡ç»“æœçš„ä¿¡æ¯
            for item in image_results_list:
                image_info = {
                    'thumbnailUrl': item.get('thumbnailUrl', 'æ— ç¼©ç•¥å›¾é“¾æ¥'),
                    'contentUrl': item.get('contentUrl', 'æ— å›¾ç‰‡é“¾æ¥'),
                    'hostPageUrl': item.get('hostPageUrl', 'æ— æ¥æºé¡µé¢é“¾æ¥'),
                    'width': item.get('width', 0),
                    'height': item.get('height', 0)
                }
                processed_results['image_results'].append(image_info)
        
        return processed_results
    def bocha_search(self,query, num_results=5, include_images=True):
        """ä½¿ç”¨Bocha APIè¿›è¡Œæœç´¢ï¼Œå¹¶è¿”å›å¤„ç†åçš„ç»“æœ
        
        :param query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        :param num_results: è¿”å›ç»“æœçš„æ•°é‡
        :param include_images: æ˜¯å¦åŒ…å«å›¾ç‰‡ç»“æœ
        :return: å¤„ç†åçš„æœç´¢ç»“æœå­—å…¸
        """
        import requests
        import json
        if not self.bocha_web_search_api:
            print("é”™è¯¯ï¼šBOCHA_WEB_SEARCH_APIç¯å¢ƒå˜é‡æœªè®¾ç½®")
            return {'web_results': [], 'image_results': []}
        
        url = "https://api.bochaai.com/v1/web-search"
        
        payload = json.dumps({
            "query": query,
            "summary": True,
            "freshness": "noLimit",
            "count": num_results,
            "page": 1
        })
        
        headers = {
            'Authorization': 'Bearer '+self.bocha_web_search_api,
            'Content-Type': 'application/json'
        }
        
        try:
            response = requests.request("POST", url, headers=headers, data=payload)
            response.raise_for_status()
            raw_results = response.json()
            
            # å¤„ç†å¹¶æå–ç»“æœ
            processed_results = self.process_bocha_results(raw_results, include_images)
            
            # æ‰“å°ç½‘é¡µæœç´¢ç»“æœæ‘˜è¦
            web_results = processed_results['web_results']
            print(f"æ‰¾åˆ° {len(web_results)} æ¡å…³äº '{query}' çš„ç½‘é¡µæœç´¢ç»“æœ:")
            for i, result in enumerate(web_results, 1):
                print(f"\n--- ç½‘é¡µç»“æœ {i} ---")
                print(f"æ ‡é¢˜: {result['title']}")
                print(f"é“¾æ¥: {result['link']}")
                print(f"æ‘˜è¦: {result['snippet'][:150]}...")
                print(f"æ€»ç»“: {result['summary'][:150]}...")
            
            # æ‰“å°å›¾ç‰‡æœç´¢ç»“æœæ‘˜è¦
            image_results = processed_results['image_results']
            if include_images:
                print(f"\næ‰¾åˆ° {len(image_results)} å¼ ç›¸å…³å›¾ç‰‡:")
                for i, img in enumerate(image_results, 1):
                    print(f"\n--- å›¾ç‰‡ {i} ---")
                    print(f"å›¾ç‰‡é“¾æ¥: {img['contentUrl']}")
                    print(f"å›¾ç‰‡å°ºå¯¸: {img['width']}x{img['height']}")
                    print(f"æ¥æºé¡µé¢: {img['hostPageUrl']}")
            
            return processed_results
            
        except Exception as e:
            print(f"æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return {'web_results': [], 'image_results': []}
        
    # ä¸‹è½½å¹¶æ˜¾ç¤ºå›¾ç‰‡çš„ç¤ºä¾‹ä»£ç 
    def download_search_images(self, query, image_results, base_dir='./search_images', max_images=15):
        """ä¸‹è½½å¹¶ä¿å­˜ Bocha æœç´¢ç»“æœä¸­çš„å›¾ç‰‡ã€‚

        :param query: åŸå§‹æœç´¢æŸ¥è¯¢ï¼Œç”¨äºåˆ›å»ºå­ç›®å½•ã€‚
        :param image_results: åŒ…å«å›¾ç‰‡ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¥è‡ª process_bocha_resultsã€‚
        :param base_dir: ä¿å­˜å›¾ç‰‡æ–‡ä»¶çš„æ ¹ç›®å½•ã€‚
        :param max_images: æœ€å¤šä¸‹è½½å‡ å¼ å›¾ç‰‡ã€‚
        """
        import requests
        import os

        if not image_results:
            print("æ²¡æœ‰å›¾ç‰‡ç»“æœå¯ä¾›ä¸‹è½½ã€‚")
            return

        # åˆ›å»ºä¿å­˜ç›®å½•
        query_dir_name = self.windows_compatible_name(query)
        save_dir = os.path.join(base_dir, query_dir_name)
        os.makedirs(save_dir, exist_ok=True)

        # Determine the effective number of images to download
        effective_max_images = min(max_images, len(image_results))

        print(f"å¼€å§‹ä¸‹è½½ '{query}' çš„å›¾ç‰‡ (æœ€å¤š {effective_max_images} å¼ ) åˆ° '{save_dir}'...")

        download_count = 0
        # Loop up to the effective maximum number of images
        for i, img in enumerate(image_results[:effective_max_images], 1):
            try:
                content_url = img.get('contentUrl')
                if not content_url:
                    print(f"  - å›¾ç‰‡ {i} ç¼ºå°‘ 'contentUrl'ï¼Œè·³è¿‡ã€‚")
                    continue

                # å°è¯•ä» URL è·å–æ–‡ä»¶åå’Œæ‰©å±•å
                try:
                    file_name_from_url = os.path.basename(requests.utils.urlparse(content_url).path)
                    # åŸºæœ¬çš„æ–‡ä»¶åæ¸…ç†å’Œæ‰©å±•åæå–
                    base, ext = os.path.splitext(file_name_from_url)
                    if not ext or len(ext) > 5: # å¦‚æœæ²¡æœ‰æ‰©å±•åæˆ–æ‰©å±•åå¤ªé•¿ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ‰©å±•å
                        # å°è¯•ä» Content-Type è·å– (è¿™éœ€è¦å‘é€ HEAD è¯·æ±‚ï¼Œå¯èƒ½è¾ƒæ…¢ï¼Œæš‚æ—¶çœç•¥)
                        # é»˜è®¤ä½¿ç”¨ .jpg æˆ–åŸºäºå·²çŸ¥ç±»å‹
                         content_type_guess = requests.head(content_url, timeout=5).headers.get('Content-Type', '').lower()
                         if 'jpeg' in content_type_guess or 'jpg' in content_type_guess:
                             ext = '.jpg'
                         elif 'png' in content_type_guess:
                             ext = '.png'
                         elif 'gif' in content_type_guess:
                             ext = '.gif'
                         elif 'webp' in content_type_guess:
                             ext = '.webp'
                         else:
                            ext = '.jpg' # Default extension
                except Exception:
                    ext = '.jpg' # Fallback extension

                # æ„å»ºæ–‡ä»¶åå’Œå®Œæ•´è·¯å¾„
                filename = f"image_{i:02d}{ext}"
                filepath = os.path.join(save_dir, filename)

                # ä¸‹è½½å›¾ç‰‡
                print(f"  - ä¸‹è½½å›¾ç‰‡ {i} ä» {content_url} ...", end='')
                response = requests.get(content_url, stream=True, timeout=10) # Added timeout
                response.raise_for_status()

                # ä¿å­˜å›¾ç‰‡
                with open(filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                
                print(f" -> å·²ä¿å­˜ä¸º {filename}")
                download_count += 1

            except requests.exceptions.RequestException as e:
                print(f" -> ä¸‹è½½å¤±è´¥ (ç½‘ç»œæˆ–è¯·æ±‚é”™è¯¯): {e}")
            except IOError as e:
                print(f" -> ä¿å­˜å¤±è´¥ (æ–‡ä»¶å†™å…¥é”™è¯¯): {e}")
            except Exception as e:
                print(f" -> å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        
        print(f"å›¾ç‰‡ä¸‹è½½å®Œæˆï¼Œå…±æˆåŠŸä¸‹è½½ {download_count} å¼ ã€‚")

    def windows_compatible_name(self,s, max_length=255):
        """
        å°†å­—ç¬¦ä¸²è½¬åŒ–ä¸ºç¬¦åˆWindowsæ–‡ä»¶/æ–‡ä»¶å¤¹å‘½åè§„èŒƒçš„åç§°ã€‚
        
        å‚æ•°:
        - s (str): è¾“å…¥çš„å­—ç¬¦ä¸²ã€‚
        - max_length (int): è¾“å‡ºå­—ç¬¦ä¸²çš„æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ä¸º255ã€‚
        
        è¿”å›:
        - str: ä¸€ä¸ªå¯ä»¥å®‰å…¨ç”¨ä½œWindowsæ–‡ä»¶/æ–‡ä»¶å¤¹åç§°çš„å­—ç¬¦ä¸²ã€‚
        """

        # Windowsæ–‡ä»¶/æ–‡ä»¶å¤¹åç§°ä¸­ä¸å…è®¸çš„å­—ç¬¦åˆ—è¡¨
        forbidden_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']

        # ä½¿ç”¨ä¸‹åˆ’çº¿æ›¿æ¢ä¸å…è®¸çš„å­—ç¬¦
        for char in forbidden_chars:
            s = s.replace(char, '_')

        # åˆ é™¤å°¾éƒ¨çš„ç©ºæ ¼æˆ–ç‚¹
        s = s.rstrip(' .')

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ä¸å…è®¸è¢«ç”¨äºæ–‡æ¡£åç§°çš„å…³é”®è¯ï¼Œå¦‚æœæœ‰çš„è¯åˆ™æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
        reserved_names = ["CON", "PRN", "AUX", "NUL", "COM1", "COM2", "COM3", "COM4", "COM5", "COM6", "COM7", "COM8", "COM9", 
                        "LPT1", "LPT2", "LPT3", "LPT4", "LPT5", "LPT6", "LPT7", "LPT8", "LPT9"]
        if s.upper() in reserved_names:
            s += '_'

        # å¦‚æœå­—ç¬¦ä¸²è¿‡é•¿ï¼Œè¿›è¡Œæˆªæ–­
        if len(s) > max_length:
            s = s[:max_length]

        return s
    
    def calculate_tokens(self,text):
        '''è®¡ç®—ç»™å®šæ–‡æœ¬çš„ token æ•°é‡'''
        # è®¡ç®— tokensï¼Œå…è´¹
        try:
            encoding = tiktoken.encoding_for_model("gpt-3.5-turbo") # æˆ–è€…ä½ ä½¿ç”¨çš„æ¨¡å‹
            return len(encoding.encode(text))
        except Exception as e:
            print(f"è­¦å‘Šï¼šä½¿ç”¨ tiktoken è®¡ç®— tokens æ—¶å‡ºé”™: {e}. è¿”å› 0ã€‚")
            return 0
        
    def save_single_bocha_result(self,result_item, query, base_dir='./auto_search'):
        """
        å¤„ç†å•ä¸ªåšæŸ¥æœç´¢ç»“æœé¡¹ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸º JSON æ–‡ä»¶ã€‚

        :param result_item: ä» process_bocha_results è¿”å›çš„åˆ—è¡¨ä¸­çš„å•ä¸ªå­—å…¸é¡¹ã€‚
                            æœŸæœ›åŒ…å« 'title', 'link', 'summary', 'snippet'ã€‚
        :param query: åŸå§‹çš„æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œç”¨äºåˆ›å»ºç›®å½•ã€‚
        :param base_dir: ä¿å­˜æ–‡ä»¶çš„æ ¹ç›®å½•ã€‚
        :return: ä¿å­˜æˆåŠŸåˆ™è¿”å›æ¸…ç†åçš„æ–‡ä»¶å (ä¸å«æ‰©å±•å)ï¼Œå¦åˆ™è¿”å› Noneã€‚
        """
        try:
            # æå–ä¿¡æ¯
            title = result_item.get('title', 'æ— æ ‡é¢˜')
            link = result_item.get('link', 'æ— é“¾æ¥')
            # ä¼˜å…ˆä½¿ç”¨ summaryï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨ snippet
            content = result_item.get('summary') or result_item.get('snippet', 'æ— å†…å®¹')
            
            # æ¸…ç†æ–‡ä»¶å
            clean_title = self.windows_compatible_name(title)
            if not clean_title: # å¦‚æœæ¸…ç†åæ ‡é¢˜ä¸ºç©ºï¼Œåˆ™è·³è¿‡
                print(f"è­¦å‘Šï¼šç»“æœ '{title}' æ¸…ç†åæ ‡é¢˜ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜ã€‚")
                return None

            tokens = self.calculate_tokens(content)
                
            # å‡†å¤‡ JSON æ•°æ®
            json_data = [{
                "link": link,
                "title": clean_title, # ä½¿ç”¨æ¸…ç†åçš„æ ‡é¢˜
                "content": content,
                "tokens": tokens
            }]
            
            # åˆ›å»ºç›®å½• (ä½¿ç”¨æ¸…ç†åçš„æŸ¥è¯¢ä½œä¸ºç›®å½•åçš„ä¸€éƒ¨åˆ†ï¼Œç¡®ä¿ç›®å½•åä¹Ÿåˆæ³•)
            query_dir_name = self.windows_compatible_name(query)
            dir_path = os.path.join(base_dir, query_dir_name)
            os.makedirs(dir_path, exist_ok=True)
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            file_path = os.path.join(dir_path, f"{clean_title}.json")
            
            # ä¿å­˜ JSON æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=4)
                
            print(f"ç»“æœå·²ä¿å­˜åˆ°: {file_path}")
            return clean_title

        except Exception as e:
            print(f"å¤„ç†å’Œä¿å­˜ç»“æœ '{result_item.get('title', 'æœªçŸ¥æ ‡é¢˜')}' æ—¶å‡ºé”™: {e}")
            return None
  
    def get_search_result(self,q):
        """
        å½“ä½ æ— æ³•å›ç­”æŸä¸ªé—®é¢˜æ—¶ï¼Œè°ƒç”¨è¯¥å‡½æ•°ï¼Œèƒ½å¤Ÿè·å¾—ç­”æ¡ˆ,ä½¿ç”¨ Bocha æœç´¢è·å–ä¿¡æ¯ï¼Œå¹¶èšåˆç»“æœå†…å®¹ç›´åˆ°è¾¾åˆ° token ä¸Šé™ã€‚
        :param q: å¿…é€‰å‚æ•°ï¼Œè¯¢é—®çš„é—®é¢˜ï¼Œå­—ç¬¦ä¸²ç±»å‹å¯¹è±¡
        :returnï¼šæŸé—®é¢˜çš„ç­”æ¡ˆï¼Œä»¥å­—ç¬¦ä¸²å½¢å¼å‘ˆç°
        """
        print(f"æ­£åœ¨ä¸ºé—®é¢˜ '{q}' æ‰§è¡Œ Bocha æœç´¢...")
        # è°ƒç”¨ bocha_searchï¼Œè¿™é‡Œæˆ‘ä»¬å¯èƒ½ä¸éœ€è¦å›¾ç‰‡ç»“æœ
        # æ³¨æ„ï¼šç¡®ä¿ä½ çš„ bocha_search å‡½æ•°è¿”å›åŒ…å« 'web_results' çš„å­—å…¸
        results_data = self.bocha_search(query=q, num_results=10, include_images=True) 
        if not results_data or not results_data.get('web_results'):
            print("æœªèƒ½è·å–åˆ°æœ‰æ•ˆçš„ç½‘é¡µæœç´¢ç»“æœã€‚")
            return "" # è¿”å›ç©ºå­—ç¬¦ä¸²æˆ–è¿›è¡Œå…¶ä»–é”™è¯¯å¤„ç†
        
        print(f"\nå¼€å§‹ä¿å­˜ '{q}' çš„æœç´¢ç»“æœ...")
        saved_count = 0
        for item in results_data['web_results']:
            saved_title = self.save_single_bocha_result(item, q)
            if saved_title:
                saved_count += 1
                print(f"\nå…±ä¿å­˜äº† {saved_count} ä¸ªç»“æœæ–‡ä»¶ã€‚")
            else:
                print("æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„ç½‘é¡µæœç´¢ç»“æœæ¥ä¿å­˜ã€‚")

        if results_data['image_results']:
            self.download_search_images(q, results_data['image_results'])
        
        num_tokens = 0
        aggregated_content = ""
        web_results = results_data['web_results']

        print(f"è·å–åˆ° {len(web_results)} æ¡ç½‘é¡µç»“æœï¼Œå¼€å§‹èšåˆå†…å®¹ (ä¸Šé™ {self.MAX_TOKENS_LIMIT} tokens)...")
        
        for i, item in enumerate(web_results):
            # ä¼˜å…ˆä½¿ç”¨ summaryï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨ snippet
            content_piece = item.get('summary') or item.get('snippet')
            
            if not content_piece: # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡æ­¤æ¡ç»“æœ
                print(f"  - ç»“æœ {i+1} ('{item.get('title', 'æ— æ ‡é¢˜')}') å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
                continue

            # è®¡ç®—è¿™æ®µå†…å®¹çš„ tokens
            current_tokens = self.calculate_tokens(content_piece)
            
            # æ£€æŸ¥æ˜¯å¦ä¼šè¶…è¿‡ä¸Šé™
            if num_tokens + current_tokens <= self.MAX_TOKENS_LIMIT:
                # è¿½åŠ å†…å®¹å’Œåˆ†éš”ç¬¦ï¼ˆä¾‹å¦‚æ¢è¡Œç¬¦ï¼‰
                aggregated_content += content_piece + "\n\n" # ä½¿ç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”ä¸åŒç»“æœ
                num_tokens += current_tokens
                print(f"  + æ·»åŠ ç»“æœ {i+1} ('{item.get('title', 'æ— æ ‡é¢˜')}'): {current_tokens} tokens (ç´¯è®¡ {num_tokens} tokens)")
            else:
                print(f"  ! ç»“æœ {i+1} ('{item.get('title', 'æ— æ ‡é¢˜')}') ({current_tokens} tokens) å°†è¶…å‡ºä¸Šé™ï¼Œåœæ­¢èšåˆã€‚")
                break # åœæ­¢æ·»åŠ å†…å®¹

        print(f"å†…å®¹èšåˆå®Œæˆï¼Œæ€»è®¡ tokens: {num_tokens}")
        return aggregated_content
    
    def get_github_readme(self,dic):

        owner = dic['owner']
        repo = dic['repo']

        headers = {
            "Authorization": self.github_token,
            "User-Agent": self.search_user_agent
        }

        response = requests.get(f"https://api.github.com/repos/{owner}/{repo}/readme", headers=headers)

        readme_data = response.json()
        encoded_content = readme_data.get('content', '')
        decoded_content = base64.b64decode(encoded_content).decode('utf-8')
        
        return decoded_content
    
    def extract_github_repos(self,search_results):
        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ç­›é€‰å‡ºé¡¹ç›®ä¸»é¡µé“¾æ¥
        repo_links = [result['link'] for result in search_results if '/issues/' not in result['link'] and '/blob/' not in result['link'] and 'github.com' in result['link'] and len(result['link'].split('/')) == 5]

        # ä»ç­›é€‰åçš„é“¾æ¥ä¸­æå–ownerå’Œrepo
        repos_info = [{'owner': link.split('/')[3], 'repo': link.split('/')[4]} for link in repo_links]

        return repos_info
    
    def get_search_text_github(self,q,dic):
        
        title = dic['owner'] + '_' + dic['repo']
        title = self.windows_compatible_name(title)

        # åˆ›å»ºé—®é¢˜ç­”æ¡ˆæ­£æ–‡
        text = self.get_github_readme(dic)

        # å†™å…¥æœ¬åœ°jsonæ–‡ä»¶
        encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")     
        json_data = [
            {
                "title": title,
                "content": text,
                "tokens": len(encoding.encode(text))
            }
        ]
        
        # è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨çš„è¯
        dir_path = f'./auto_search/{q}'
        os.makedirs(dir_path, exist_ok=True)
        
        with open('./auto_search/%s/%s.json' % (q, title), 'w') as f:
            json.dump(json_data, f)

        return title
    
    def get_answer(self,q, g='globals()'):
        """
        å½“ä½ æ— æ³•å›ç­”æŸä¸ªé—®é¢˜æ—¶ï¼Œè°ƒç”¨è¯¥å‡½æ•°ï¼Œèƒ½å¤Ÿè·å¾—ç­”æ¡ˆ
        :param q: å¿…é€‰å‚æ•°ï¼Œè¯¢é—®çš„é—®é¢˜ï¼Œå­—ç¬¦ä¸²ç±»å‹å¯¹è±¡
        :param g: gï¼Œå­—ç¬¦ä¸²å½¢å¼å˜é‡ï¼Œè¡¨ç¤ºç¯å¢ƒå˜é‡ï¼Œæ— éœ€è®¾ç½®ï¼Œä¿æŒé»˜è®¤å‚æ•°å³å¯
        :returnï¼šæŸé—®é¢˜çš„ç­”æ¡ˆï¼Œä»¥å­—ç¬¦ä¸²å½¢å¼å‘ˆç°
        """
        # é»˜è®¤æœç´¢è¿”å›5ä¸ªç­”æ¡ˆ
        print('æ­£åœ¨æ¥å…¥åšæŸ¥æœç´¢ï¼ŒæŸ¥æ‰¾å’Œé—®é¢˜ç›¸å…³çš„ç­”æ¡ˆ...')
        
        return self.get_search_result(q)
    
    def get_answer_github(self,q, g='globals()'):
        """
        å½“ä½ æ— æ³•å›ç­”æŸä¸ªé—®é¢˜æ—¶ï¼Œè°ƒç”¨è¯¥å‡½æ•°ï¼Œèƒ½å¤Ÿè·å¾—ç­”æ¡ˆ
        :param q: å¿…é€‰å‚æ•°ï¼Œè¯¢é—®çš„é—®é¢˜ï¼Œå­—ç¬¦ä¸²ç±»å‹å¯¹è±¡
        :param g: gï¼Œå­—ç¬¦ä¸²å½¢å¼å˜é‡ï¼Œè¡¨ç¤ºç¯å¢ƒå˜é‡ï¼Œæ— éœ€è®¾ç½®ï¼Œä¿æŒé»˜è®¤å‚æ•°å³å¯
        :returnï¼šæŸé—®é¢˜çš„ç­”æ¡ˆï¼Œä»¥å­—ç¬¦ä¸²å½¢å¼å‘ˆç°
        """
        
        # é»˜è®¤æœç´¢è¿”å›5ä¸ªç­”æ¡ˆ
        print('æ­£åœ¨æ¥å…¥è°·æ­Œæœç´¢ï¼ŒæŸ¥æ‰¾å’Œé—®é¢˜ç›¸å…³çš„ç­”æ¡ˆ...')
        search_results = self.google_search(query=q, num_results=5, site_url='https://github.com/')
        results = self.extract_github_repos(search_results)
        
        # åˆ›å»ºå¯¹åº”é—®é¢˜çš„å­æ–‡ä»¶å¤¹
        folder_path = './auto_search/%s' % q
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
        
        print('æ­£åœ¨è¯»å–ç›¸å…³é¡¹ç›®è¯´æ˜æ–‡æ¡£...')
        num_tokens = 0
        content = ''
        
        for dic in results:
            title = self.get_search_text_github(q, dic)
            with open('./auto_search/%s/%s.json' % (q, title), 'r') as f:
                jd = json.load(f)
            num_tokens += jd[0]['tokens']
            if num_tokens <= self.MAX_TOKENS_LIMIT:
                content += jd[0]['content']
            else:
                break
        print('æ­£åœ¨è¿›è¡Œæœ€åçš„æ•´ç†...')
        return(content)
    
    def print_code_if_exists(self,function_args):
        """
        å¦‚æœå­˜åœ¨ä»£ç ç‰‡æ®µï¼Œåˆ™æ‰“å°ä»£ç 
        """
        def convert_to_markdown(code, language):
            return f"```{language}\n{code}\n```"
        
        # å¦‚æœæ˜¯SQLï¼Œåˆ™æŒ‰ç…§Markdownä¸­SQLæ ¼å¼æ‰“å°ä»£ç 
        if function_args.get('sql_query'):
            code = function_args['sql_query']
            markdown_code = convert_to_markdown(code, 'sql')
            print("å³å°†æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š")
            print(markdown_code)

        # å¦‚æœæ˜¯Pythonï¼Œåˆ™æŒ‰ç…§Markdownä¸­Pythonæ ¼å¼æ‰“å°ä»£ç 
        elif function_args.get('py_code'):
            code = function_args['py_code']
            markdown_code = convert_to_markdown(code, 'python')
            print("å³å°†æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š")
            print(markdown_code)

    def create_function_response_messages(self,messages, response):
    
        """
        è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œå¹¶æ›´æ–°æ¶ˆæ¯åˆ—è¡¨
        :param messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
        :param response: æ¨¡å‹æŸæ¬¡åŒ…å«å¤–éƒ¨å·¥å…·è°ƒç”¨è¯·æ±‚çš„å“åº”ç»“æœ
        :returnï¼šmessagesï¼Œè¿½åŠ äº†å¤–éƒ¨å·¥å…·è¿è¡Œç»“æœåçš„æ¶ˆæ¯åˆ—è¡¨
        """

        available_functions = {
            "python_inter": self.python_inter,
            "fig_inter": self.fig_inter,
            "sql_inter": self.sql_inter,
            "extract_data": self.extract_data,
            "get_answer": self.get_answer,
            "get_answer_github": self.get_answer_github,
        }
        
        # æå–function call messages
        function_call_messages = response.choices[0].message.tool_calls

        # å°†function call messagesè¿½åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
        messages.append(response.choices[0].message.model_dump())

        # æå–æœ¬æ¬¡å¤–éƒ¨å‡½æ•°è°ƒç”¨çš„æ¯ä¸ªä»»åŠ¡è¯·æ±‚
        for function_call_message in function_call_messages:
            
            # æå–å¤–éƒ¨å‡½æ•°åç§°
            tool_name = function_call_message.function.name
            # æå–å¤–éƒ¨å‡½æ•°å‚æ•°
            tool_args = json.loads(function_call_message.function.arguments)       
            
            # æŸ¥æ‰¾å¤–éƒ¨å‡½æ•°
            fuction_to_call = available_functions[tool_name]

            # æ‰“å°ä»£ç 
            self.print_code_if_exists(function_args=tool_args)

            # è¿è¡Œå¤–éƒ¨å‡½æ•°
            try:
                tool_args['g'] = globals()
                print(f"[è°ƒè¯•] æ­£åœ¨æ‰§è¡Œå·¥å…· {tool_name} å‚æ•°: {tool_args}")
                function_response = fuction_to_call(**tool_args)
                print(f"[è°ƒè¯•] å·¥å…·æ‰§è¡Œç»“æœ: {function_response[:100]}...")
            except Exception as e:
                error_msg = f"å‡½æ•°è¿è¡ŒæŠ¥é”™å¦‚ä¸‹: {e}"
                function_response = error_msg
                print(f"[é”™è¯¯] {error_msg}")

            # æ‹¼æ¥æ¶ˆæ¯é˜Ÿåˆ—
            messages.append(
                {
                    "role": "tool",
                    "content": function_response,
                    "tool_call_id": function_call_message.id,
                }
            )
            
        return messages     
    
    def chat_base(self, messages, client, model):
        """è·å¾—ä¸€æ¬¡æ¨¡å‹å¯¹ç”¨æˆ·çš„å“åº”ã€‚"""
        
        # æ£€æŸ¥æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«æ•°æ®åº“å…³é”®è¯
        last_user_msg = None
        for msg in reversed(messages):
            if msg["role"] == "user":
                last_user_msg = msg["content"]
                break
        
        if last_user_msg:
            print(f"[è°ƒè¯•] æœ€åçš„ç”¨æˆ·æ¶ˆæ¯: {last_user_msg}")
            db_keywords = ["æ•°æ®åº“", "è¡¨", "æ·»åŠ æ•°æ®", "æ’å…¥", "åˆ›å»ºè¡¨"]
            detected_keywords = [kw for kw in db_keywords if kw in last_user_msg]
            if detected_keywords:
                print(f"[è°ƒè¯•] æ£€æµ‹åˆ°æ•°æ®åº“å…³é”®è¯: {detected_keywords}")
        
        try:
            print("[è°ƒè¯•] å‘é€è¯·æ±‚ç»™API...")
            response = client.chat.completions.create(
                model=model,  
                messages=messages,
                tools=self.tools,
            )
            print(f"[è°ƒè¯•] æ”¶åˆ°å“åº”ï¼Œfinish_reason: {response.choices[0].finish_reason}")
            
            # å¦‚æœæ²¡æœ‰è°ƒç”¨å·¥å…·ä½†æœ€åçš„æ¶ˆæ¯åŒ…å«æ•°æ®åº“å…³é”®è¯ï¼Œå°è¯•æ‰“å°æ¨¡å‹çš„æ€è€ƒ
            if response.choices[0].finish_reason != "tool_calls" and detected_keywords:
                print(f"[è­¦å‘Š] æ£€æµ‹åˆ°æ•°æ®åº“ç›¸å…³å…³é”®è¯ä½†æ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·! æ¨¡å‹è¿”å›: {response.choices[0].message.content[:100]}...")
            
        except Exception as e:
            print("æ¨¡å‹è°ƒç”¨æŠ¥é”™" + str(e))
            return None

        if response.choices[0].finish_reason == "tool_calls":
            print(f"[è°ƒè¯•] æ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·: {[t.function.name for t in response.choices[0].message.tool_calls]}")
            while True:
                messages = self.create_function_response_messages(messages, response)
                response = client.chat.completions.create(
                    model=model,  
                    messages=messages,
                    tools=self.tools,
                )
                if response.choices[0].finish_reason != "tool_calls":
                    break
        
        return response

    def save_markdown_to_file(self,content: str, filename_hint: str, directory="research_task"):
        # åœ¨å½“å‰é¡¹ç›®ç›®å½•ä¸‹åˆ›å»º research_task æ–‡ä»¶å¤¹
        save_dir = os.path.join(os.getcwd(), directory)

        # å¦‚æœç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
        os.makedirs(save_dir, exist_ok=True)

        # åˆ›å»ºæ–‡ä»¶åï¼ˆå–å‰8ä¸ªå­—ç¬¦å¹¶åŠ ä¸Š...ï¼‰
        filename = f"{filename_hint[:8]}....md"

        # å®Œæ•´æ–‡ä»¶è·¯å¾„
        file_path = os.path.join(save_dir, filename)

        # å°†å†…å®¹ä¿å­˜ä¸ºMarkdownæ–‡æ¡£
        with open(file_path, 'w', encoding='utf-8') as file:
            file.write(content)

        print(f"æ–‡ä»¶å·²æˆåŠŸä¿å­˜åˆ°ï¼š{file_path}")

    def chat(self):
        print("ä½ å¥½ï¼Œæˆ‘æ˜¯å‘¨æµ©æ´‹åˆ¶ä½œçš„`VastOcean`ï¼Œæœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„ï¼Ÿ")
        while True:
            question = input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜(è¾“å…¥é€€å‡ºä»¥ç»“æŸå¯¹è¯): ")
            if question == "é€€å‡º":
                break  
            print(f"[è°ƒè¯•] å½“å‰æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦: {len(self.messages)}")
            self.messages.append({"role": "user", "content": question})
            self.messages = self.messages[-20: ]
            
            response = self.chat_base(messages=self.messages, 
                                 client=self.client, 
                                 model=self.MODEL)
            
            # æ·»åŠ å¯¹responseä¸ºNoneçš„æ£€æŸ¥
            if response is None:
                print("***`VastOcean:`*** è¿æ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
                continue
            
            print("***`VastOcean:`***" + response.choices[0].message.content)
            self.messages.append(response.choices[0].message)
            
    def research_task_simple(self, question):
        """
        ç®€å•ç ”ç©¶ä»»åŠ¡
        """
        response = self.client.chat.completions.create(model=self.MODEL,
                                                  messages=[{"role": "user", "content": self.prompt_style1.format(question)}])
        
        print("***`VastOcean:`***" + response.choices[0].message.content)

        new_messages = [
            {"role": "user", "content": question},
            response.choices[0].message.model_dump()
        ]
        
        new_question = input("è¯·è¾“å…¥æ‚¨çš„è¡¥å……è¯´æ˜(è¾“å…¥é€€å‡ºä»¥ç»“æŸå¯¹è¯): ")
        if new_question == "é€€å‡º":
            return None
        else:
            new_messages.append({"role": "user", "content":self.prompt_style2.format(new_question)})
            
            second_response = self.chat_base(messages=new_messages, 
                                        client=self.client, 
                                        model=self.MODEL)
            
            print("***`VastOcean:`***" + second_response.choices[0].message.content)
            
            self.save_markdown_to_file(content=second_response.choices[0].message.content, 
                                  filename_hint=question)
            
    async def research_task_deep(self, query:str):
        """
        æ·±åº¦ç ”ç©¶ä»»åŠ¡
        """
        # Indicate that the research process is starting
        print("***`VastOcean:`***" +"Starting research...")
        # Step 1: Generate search plan using planner_agent
        search_plan = await self.plan_searches(query)
        # Step 2: Perform the searches using search_agent
        search_results = await self.perform_searches(search_plan)
        # Step 3: Write the final report using writer_agent
        report = await self.write_report(query, search_results)

        # Final printed report
        print("\n\n=====REPORT=====\n\n")
        print(report.markdown_report)
        print("\n\n=====FOLLOW UP QUESTIONS=====\n\n")
        follow_up_questions = "\n".join(report.follow_up_questions)
        print(follow_up_questions)
         # ä¿å­˜ä¸º Markdown æ–‡ä»¶
        self.save_report_as_md(query, report.markdown_report)
    
    async def plan_searches(self, query: str) -> WebSearchPlan:
        print("Planning searches...")
        result = await Runner.run(
            self.planner_agent,
            f"Query: {query}",
        )
        return result.final_output_as(WebSearchPlan)
    async def perform_searches(self, search_plan: WebSearchPlan) -> list[str]:
        print("Starting searching...")
        num_completed = 0
        tasks = [asyncio.create_task(self.search(item)) for item in search_plan.searches]
        results = []
        for task in asyncio.as_completed(tasks):
            result = await task
            if result is not None:
                results.append(result)
            num_completed += 1
            print(f"Searching... {num_completed}/{len(tasks)} completed")
        return results
    async def search(self, item: WebSearchItem) -> str | None:
        print(f"Search term: {item.query}\nReason for searching: {item.reason}")
        try:
            result = await Runner.run(
                self.search_agent,
                input=f"Search term: {item.query}\nReason for searching: {item.reason}"
            )
            return str(result.final_output)
        except Exception:
            return None
    async def write_report(self, query: str, search_results: list[str]) -> ReportData:
        print("Thinking about report...")
        print(f"Original query: {query}\nSummarized search results: {search_results}")
        
        # Use run instead of run_streamed to avoid async context issues
        result = await Runner.run(
            self.writer_agent,
            input=f"Original query: {query}\nSummarized search results: {search_results}",
        )
        # ç”¨äºåœ¨ç”ŸæˆæŠ¥å‘Šæ—¶æ˜¾ç¤ºè¿›åº¦çš„æ¶ˆæ¯åˆ—è¡¨
        update_messages = [
            "Thinking about report...",
            "Planning report structure...",
            "Writing outline...",
            "Creating sections...",
            "Cleaning up formatting...",
            "Finalizing report...",
            "Finishing report...",
        ]

        last_update = time.time() # è®°å½•ä¸Šæ¬¡æ›´æ–°æ¶ˆæ¯çš„æ—¶é—´
        next_message = 0# ä¸‹ä¸€ä¸ªè¦æ˜¾ç¤ºçš„æ¶ˆæ¯ç´¢å¼•
        for _ in result.new_items:# è¿­ä»£ä»£ç†è¿è¡Œäº§ç”Ÿçš„æ–°é¡¹ç›®ï¼ˆå¯èƒ½æ˜¯ä¸­é—´æ­¥éª¤æˆ–çŠ¶æ€ï¼‰
            # å¦‚æœè·ç¦»ä¸Šæ¬¡æ›´æ–°è¶…è¿‡5ç§’ï¼Œå¹¶ä¸”è¿˜æœ‰æœªæ˜¾ç¤ºçš„æ¶ˆæ¯
            if time.time() - last_update > 5 and next_message < len(update_messages):
                print(update_messages[next_message])
                next_message += 1
                last_update = time.time()
        # è¿”å›æœ€ç»ˆçš„æŠ¥å‘Šæ•°æ®
        return result.final_output_as(ReportData)
    def save_report_as_md(self, query: str, markdown_content: str) -> None:
        """
        ä¿å­˜ç”Ÿæˆçš„æŠ¥å‘Šä¸º Markdown æ–‡ä»¶
        """
        # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        folder_name = "research_reports"
        if not os.path.exists(folder_name):
            os.makedirs(folder_name)

        # ä½¿ç”¨ç”¨æˆ·çš„æŸ¥è¯¢ä½œä¸ºæ–‡ä»¶å
        sanitized_query = query.replace(" ", "_").replace("ï¼š", "").replace("?", "")
        file_name = f"{folder_name}/å…³äº{sanitized_query}è°ƒç ”æŠ¥å‘Š.md"

        # å†™å…¥ Markdown æ–‡ä»¶
        with open(file_name, "w", encoding="utf-8") as file:
            file.write(markdown_content)

        print(f"Report saved as: {file_name}")
    def clear_messages(self):
        self.messages = []

def main():
    while True:
        vastOcean = VastOcean()
        os.system('cls')
        print("æ¬¢è¿æ¥åˆ°å‘¨æµ©æ´‹'s VastOcean!")
        print("è¯·é€‰æ‹©åŠŸèƒ½(è¾“å…¥æ•°å­—1/2/3/4):")
        print("1.chat with tools")
        print("2.deep research(bocha version)")    
        print("3.deep research(openai version)")
        print("4.exit")
        char = input()
        if char == '1':
            vastOcean.chat()
        elif char == '2':
            question = input("è¯·è¾“å…¥ä½ è¦æ·±åº¦ç ”ç©¶çš„ä»»åŠ¡:")
            vastOcean.research_task_simple(question)
        elif char == '3':
            question = input("è¯·è¾“å…¥ä½ è¦æ·±åº¦ç ”ç©¶çš„ä»»åŠ¡:")
            # Use asyncio.run() to execute the async function
            try:
                asyncio.run(vastOcean.research_task_deep(question))
            except Exception as e:
                print(f"æ·±åº¦ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}") # Add error handling
        elif char == '4':
            print("å®‰å…¨é€€å‡ºï¼")
            break
        else:
            print("è¾“å…¥æ ¼å¼ä¸åˆæ³•ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
            os.system('cls')
    
if __name__=='__main__':  # è¿™é‡Œåº”è¯¥æ˜¯åŒä¸‹åˆ’çº¿__main__ï¼Œè€Œä¸æ˜¯main
    main()

